LLM-based Query-to-SQL 実装用設計ドキュメント
1. システム概要
ユーザー入力
ユーザーが自然言語でデータベースから取得したい情報を入力する。
（例：「2023年のプレミアリーグでリバプールの選手別ゴール数を降順で教えて」）

SQL 生成（OpenAI GPT を利用）
システムは入力されたクエリとDBスキーマ情報をプロンプトに含め、GPTに適切なSQL文を作成させる。

SQL 実行 & 結果取得
生成されたSQL文をDBに投げ、結果を取得する。

ユーザーへの回答 or 追加情報要求

成功時：クエリ結果をテキスト化してユーザーに返す
失敗/情報不足時：ユーザーに追加情報を尋ねる、または簡単なエラー表示
本システムでは「継続的な会話スレッド管理」は不要とし、1回のユーザー問い合わせ→SQL生成→実行結果返却の単純フローで実装する。

2. 前提・想定
DBスキーマがある程度固定（テーブル名とカラム名は事前にLLMプロンプトへ提供）
ユーザーからのクエリは1回きりで十分とする（チャット的な会話状態は保持しない）
セキュリティ：読み取り専用DBユーザーを想定し、万一の危険なSQL生成を防ぐ。
エラー対応：LLMが誤ったSQLを生成した場合はエラーを検知し、ユーザーに「うまく実行できませんでした」と返す程度の簡易実装とする。
3. システム構成
3.1 コンポーネント
フロントエンド（またはCLI）

シンプルにユーザーの1文テキストを入力し、結果を表示するだけ。
Webフォーム or CLI など問わない。最低限「問い合わせ送信→結果表示」があればOK。
バックエンド (Python)

OpenAI SDK を利用し、LLM(GPT)を呼び出す。
DBクライアント を用い、生成されたSQLを実行する。
「クエリ生成→SQL実行→結果整形→ユーザーへの返答」を1ステップで処理する簡易フロー。
3.2 データベース
例：PostgreSQL, MySQL, SQLite 等
テーブル例：players, teams, matches, stats など
事前に DB_SCHEMA_DESCRIPTION という形で「テーブル名」「主なカラム」「主キー・外部キーの簡易説明」を文字列にまとめ、LLMプロンプトに埋め込む。
4. 処理フロー
ステップ1. ユーザー入力取得
フロント or CLIで入力された文字列を受け取る。
例：query_text = "2023年のプレミアリーグでリバプールの選手別ゴール数を多い順に教えて"
ステップ2. プロンプト生成
生成したいSQLの条件をプロンプトとして作成。
大まかな例：
python
コードをコピーする
prompt_text = f"""
You are a helpful assistant that generates valid SQL queries for the following database schema:
{DB_SCHEMA_DESCRIPTION}

User query: "{query_text}"

Requirements:
- Return only the SQL statement (no explanation).
- Make sure to reference only the tables and columns in the schema.
- The user wants the data sorted by goals descending, etc...
"""
このようにプロンプトにはDBスキーマ情報を含め、ユーザーの要望を添える。
ステップ3. OpenAI GPT からSQL生成
openai.ChatCompletion.create() などを利用し、prompt_text を送信。
GPTから返ってくるレスポンスをパースし、SQL文文字列を取り出す。
例：
sql
コードをコピーする
SELECT players.name, SUM(stats.goals) AS total_goals
FROM players
JOIN teams ON ...
WHERE ...
GROUP BY ...
ORDER BY total_goals DESC;
ステップ4. SQL実行
DB接続してSQLを実行し、結果を取得。
失敗/エラーの場合：
LLMによる誤ったSQLか、ユーザーの要望がスキーマ外かもしれない。
「実行できませんでした」とユーザーに伝えて終了（または再入力を促す）。
ステップ5. 結果整形と返却
実行結果が得られたら、Python側でテーブル形式やリスト形式に整形。

シンプルにテキスト化してユーザーに表示する。
例：

markdown
コードをコピーする
リバプールの2023年プレミアリーグ ゴール数ランキング:
 1. Mohamed Salah - 19ゴール
 2. Darwin Núñez - 15ゴール
 ...
もし列数が多い場合や、ユーザーが追加情報を必要とする場合は簡易的な再質問プロンプトを用意してもよい。
ただし今回の要件では単発クエリ想定なので、最低限は結果をそのまま返すだけでよい。

5. 想定コード構成（ディレクトリ例）
bash
コードをコピーする
project_root/
├─ main.py               # メイン実行スクリプト
├─ requirements.txt      # ライブラリ依存関係 (openai, psycopg2/mysqlclient等)
├─ config.py             # OpenAI APIキー/DB接続情報
├─ db_util.py            # DB接続・SQL実行関数
└─ prompt_builder.py     # プロンプト文生成ロジック
main.py
python main.py で実行し、ユーザーの入力を受け取り、全処理を回す流れ。
config.py
APIキーやDB接続情報（ホスト名、ユーザー名、パスワード、DB名など）をまとめる。環境変数でも可。
db_util.py
execute_sql(sql_text) のような関数を用意し、DB接続～SQL実行～結果取得を担当。
prompt_builder.py
DBスキーマ文字列を用意し、ユーザー入力からプロンプト文を組み立てる関数を持つ。
6. 簡易エラー/例外ハンドリング
LLMのSQL生成エラー
LLMが意味不明な回答をしたり、SQLでない文章を返すケース。
→ if not sql_text.lower().startswith("select"): return "SQLが生成できませんでした"などの簡易チェック。
DB実行エラー
カラム名やテーブル名間違いなどでSQLが失敗。
→ 例外キャッチしてユーザーに「実行に失敗しました」と返す。
結果なし
実行自体は成功だが行が返らない。
→ 「該当するデータはありませんでした」と表示して終了。
7. 留意点
SQLインジェクション：
原則LLMが生成するのは読み取り専用クエリに限定し、DBユーザーにもINSERT/UPDATE権限を与えない。
DBスキーマの更新：
スキーマが変わったらプロンプトの DB_SCHEMA_DESCRIPTION も更新する必要がある。
幻覚 / Hallucination：
LLMが存在しないテーブルやカラムを使おうとする場合があるので、実行エラー時は丁寧にハンドリングする。
パフォーマンス要件：
今回は単発クエリ想定なので大きな問題になりにくい。
8. 実装ステップまとめ
DBセットアップ & テストデータ投入
OpenAI API キーを環境変数 or configファイルで設定
DBスキーマ説明を prompt_builder.py に定義
main.py でユーザー入力→プロンプト生成→LLM呼び出し→SQL実行→結果返却
エラー時の挙動を最低限カバー
シンプルに結果を表示して動作確認